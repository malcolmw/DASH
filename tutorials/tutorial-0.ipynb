{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4e0f84e7-5a8e-481d-b1ec-2bb71059f72b",
   "metadata": {},
   "source": [
    "# Tutorial-0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e96100d-f5d6-498c-bdd5-974c295b537a",
   "metadata": {},
   "source": [
    "This first exercise demonstrates how to create an empty HDF5eis file and add a single channel of data to it. To begin, let's import some necessary packages for this tutorial and create a directory where we can write some data files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d4bd495b-a6b6-425b-9039-dac479f6e184",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard library imports\n",
    "import io\n",
    "import pathlib\n",
    "\n",
    "# Third-party imports\n",
    "import hdf5eis\n",
    "import obspy.clients.fdsn\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "OUTPUT_DIR = pathlib.Path(\"/home/malcolmw/scratch/hdf5eis_tutorial\")\n",
    "OUTPUT_DIR.mkdir(exist_ok=True, parents=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80724a5f-4acb-4a16-a470-60177ee43143",
   "metadata": {},
   "source": [
    "Core functionality for manipulating HDF5eis files is accessed via the `hdf5eis.File` class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "be9328e4-bb5b-4ca1-bdf5-1382fc1e1325",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mInit signature:\u001b[0m \u001b[0mhdf5eis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moverwrite\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m     \n",
       "An h5py.File subclass for convenient I/O of big, multidimensional\n",
       "timeseries data from environmental sensors. This class provides\n",
       "the core functionality for manipulating HDF5eis files.\n",
       "\u001b[0;31mInit docstring:\u001b[0m\n",
       "Initialize hdf5eis.File object.\n",
       "\n",
       "Parameters\n",
       "----------\n",
       "*args :\n",
       "    These are passed directly to the super class initializer.\n",
       "    Must contain a file path (str or bytes) or a file-like\n",
       "    object.\n",
       "overwrite : bool, optional\n",
       "    Whether or not to overwrite an existing file if one exists\n",
       "    at the given location. The default is False.\n",
       "**kwargs :\n",
       "    These are passed directly to super class initializer.\n",
       "\n",
       "Raises\n",
       "------\n",
       "\n",
       "    ValueError if mode=\"w\" and file already exists.\n",
       "\n",
       "Returns\n",
       "-------\n",
       "    None.\n",
       "\u001b[0;31mFile:\u001b[0m           /opt/tljh/user/envs/devel/lib/python3.9/site-packages/hdf5eis/core.py\n",
       "\u001b[0;31mType:\u001b[0m           ABCMeta\n",
       "\u001b[0;31mSubclasses:\u001b[0m     \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "hdf5eis.File?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a491904-6af5-4514-af94-b989f3ddf202",
   "metadata": {},
   "source": [
    "Let's create an empty HDF5eis file. The default `mode` is `\"r\"`, so to create a new file we need to specify `mode=\"w\"` or `mode=\"a\"`. Note that the `hdf5eis.File` class inherits from the `h5py.File` class and passes `*args` and `**kwargs` to its super-class initializer. Any valid positional or keyword arguments for the `h5py.File` intializer are therefore valid for `hdf5eis.File` as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "579d7ff9-ed12-45ac-8598-bb215ca3b52e",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_out = hdf5eis.File(OUTPUT_DIR.joinpath(\"my_first_file.hdf5\"), mode=\"a\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "489f42ef-6b05-4f25-a0a5-deb174c7ba13",
   "metadata": {},
   "source": [
    "`hdf5eis.File` instances have three properties (`timeseries`, `metadata`, and `products`) which provide functionality to manipulate the groups by the same name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bb07356a-efbb-4fee-8446-20158872b7e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mType:\u001b[0m        property\n",
       "\u001b[0;31mString form:\u001b[0m <property object at 0x7f07aafaf860>\n",
       "\u001b[0;31mDocstring:\u001b[0m  \n",
       "Provides functionality to manipulate the  \"/timeseries\"\n",
       "group.\n",
       "\n",
       "Returns\n",
       "-------\n",
       "hdf5eis.TimeseriesAccessor\n",
       "    Provides functionality to manipulate the  \"/timeseries\"\n",
       "    group.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "file_out.timeseries?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9142f25e-3bf1-4d5b-90fe-dab0604ed039",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mType:\u001b[0m        property\n",
       "\u001b[0;31mString form:\u001b[0m <property object at 0x7f07aaf93950>\n",
       "\u001b[0;31mDocstring:\u001b[0m  \n",
       "Provides functionality to manipulate the  \"/metadata\"\n",
       "group.\n",
       "\n",
       "Returns\n",
       "-------\n",
       "hdf5eis.AuxiliaryAccessor\n",
       "    Provides functionality to manipulate the  \"/metadata\"\n",
       "    group.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "file_out.metadata?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "480034f8-06d9-4947-b545-4cd46038de13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mType:\u001b[0m        property\n",
       "\u001b[0;31mString form:\u001b[0m <property object at 0x7f07aafaf810>\n",
       "\u001b[0;31mDocstring:\u001b[0m  \n",
       "Provides functionality to manipulate the  \"/products\"\n",
       "group.\n",
       "\n",
       "Returns\n",
       "-------\n",
       "hdf5eis.AuxiliaryAccessor\n",
       "    Provides functionality to manipulate the  \"/products\"\n",
       "    group.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "file_out.products?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d10fc9b3-52f9-4490-b573-b729fb8e6892",
   "metadata": {},
   "source": [
    "The `hdf5eis.File.timeseries` property has an `index` property that records the contents of the group. At present, it is empty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e4b9a4db-47b5-4bb4-a8ef-0685a3cd1df3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tag</th>\n",
       "      <th>start_time</th>\n",
       "      <th>end_time</th>\n",
       "      <th>sampling_rate</th>\n",
       "      <th>npts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [tag, start_time, end_time, sampling_rate, npts]\n",
       "Index: []"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_out.timeseries.index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5502c464-411e-4b56-b320-0eecabe16ac3",
   "metadata": {},
   "source": [
    "Let's download some timeseries data to add to the file. We will download one hour of data from IRIS for channel `AZ.BZN..HHZ`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "78fc04c3-878c-47f9-80cf-01aebfda17f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "network = \"AZ\"\n",
    "station = \"BZN\"\n",
    "location = \"\"\n",
    "channel = \"HHZ\"\n",
    "start_time = obspy.UTCDateTime(\"2021-01-01T00:00:00Z\")\n",
    "end_time = obspy.UTCDateTime(\"2021-01-01T01:00:00Z\")\n",
    "client = obspy.clients.fdsn.Client()\n",
    "stream = client.get_waveforms(\n",
    "    network,\n",
    "    station,\n",
    "    location,\n",
    "    channel,\n",
    "    start_time,\n",
    "    end_time\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9df6f6de-3800-45ef-97a4-63275087fb7d",
   "metadata": {},
   "source": [
    "We can add the data using the `add` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "26849181-cdb1-4d28-b5a9-4ca6c6fb2f38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m \u001b[0mfile_out\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeseries\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msampling_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtag\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m\n",
       "Add timeseries data to the parent HDF5eis file.\n",
       "\n",
       "Parameters\n",
       "----------\n",
       "data : array-like\n",
       "    Data array of any shape to add to file.\n",
       "start_time : str, int, float, or pandas.Timestamp\n",
       "    The UTC time of the first sample in data. This value is\n",
       "    internally converted to a pandas.Timestamp by\n",
       "    pandas.to_datetime().\n",
       "sampling_rate : int, float\n",
       "    The temporal sampling rate of data in units of samples per\n",
       "    second.\n",
       "tag : str, optional\n",
       "    Tag to associate with data. The default is \"\".\n",
       "**kwargs :\n",
       "    Additional keyword arguments are passed directly the\n",
       "    h5py.Group.create_datset() method and can be used, for\n",
       "    example, to choose the chunk layout and compression options.\n",
       "\n",
       "Returns\n",
       "-------\n",
       "None.\n",
       "\u001b[0;31mFile:\u001b[0m      /opt/tljh/user/envs/devel/lib/python3.9/site-packages/hdf5eis/core.py\n",
       "\u001b[0;31mType:\u001b[0m      method\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "file_out.timeseries.add?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "456e2681-45a8-4ce8-99e5-819a0095d961",
   "metadata": {},
   "outputs": [],
   "source": [
    "for trace in stream:\n",
    "    file_out.timeseries.add(\n",
    "        trace.data,\n",
    "        str(trace.stats.starttime),\n",
    "        trace.stats.sampling_rate,\n",
    "        tag=\".\".join((network, station, location, channel))\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "228e983a-84d4-41de-a8cf-70e62eea231c",
   "metadata": {},
   "source": [
    "Now we can see that there is a corresponding row in the timeseries index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "803fb359-d922-4190-88ef-1ddeff2062e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tag</th>\n",
       "      <th>start_time</th>\n",
       "      <th>end_time</th>\n",
       "      <th>sampling_rate</th>\n",
       "      <th>npts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AZ.BZN..HHZ</td>\n",
       "      <td>2021-01-01 00:00:00.008400+00:00</td>\n",
       "      <td>2021-01-01 00:59:59.998400+00:00</td>\n",
       "      <td>100.0</td>\n",
       "      <td>360000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           tag                       start_time  \\\n",
       "0  AZ.BZN..HHZ 2021-01-01 00:00:00.008400+00:00   \n",
       "\n",
       "                          end_time  sampling_rate    npts  \n",
       "0 2021-01-01 00:59:59.998400+00:00          100.0  360000  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_out.timeseries.index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07f78782-31ab-4728-b4a6-c57e1c281f0d",
   "metadata": {},
   "source": [
    "We can retrieve the data now using a hybrid of dictionary-like and array-slicing syntax."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "caa15b3c-a474-41db-82be-737ed8f7a147",
   "metadata": {},
   "outputs": [],
   "source": [
    "super_gather = file_out.timeseries[\"AZ.BZN..HHZ\", \"2021-01-01T00:00:00Z\": \"2021-01-01T00:30:00Z\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f412978b-2781-4940-9840-2036ac7a479a",
   "metadata": {},
   "source": [
    "Timeseries data are returned as a dictionary in which the key is the `tag` associated with the corresponding value and the value is a list of `hdf5eis.Gather` objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b0f2bc4c-171a-43f3-abf3-8808cb272f0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'AZ.BZN..HHZ': [<hdf5eis.gather.Gather at 0x7f09aa74a430>]}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "super_gather"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cc415a0-eb58-40cd-afbf-8859230b32d4",
   "metadata": {},
   "source": [
    "Each `hdf5eis.Gather` object has a number of descriptive properties (a subset is demonstrated here)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3af25005-1d3b-43a6-b211-7c28144f9b39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gather.data: [ 716  693  700 ... 1247 1303 1395]\n",
      "gather.starttime: 2021-01-01 00:00:00.008400+00:00\n",
      "gather.times: DatetimeIndex(['2021-01-01 00:00:00.008400+00:00',\n",
      "               '2021-01-01 00:00:00.018400+00:00',\n",
      "               '2021-01-01 00:00:00.028400+00:00',\n",
      "               '2021-01-01 00:00:00.038400+00:00',\n",
      "               '2021-01-01 00:00:00.048400+00:00',\n",
      "               '2021-01-01 00:00:00.058400+00:00',\n",
      "               '2021-01-01 00:00:00.068400+00:00',\n",
      "               '2021-01-01 00:00:00.078400+00:00',\n",
      "               '2021-01-01 00:00:00.088400+00:00',\n",
      "               '2021-01-01 00:00:00.098400+00:00',\n",
      "               ...\n",
      "               '2021-01-01 00:29:59.908400+00:00',\n",
      "               '2021-01-01 00:29:59.918400+00:00',\n",
      "               '2021-01-01 00:29:59.928400+00:00',\n",
      "               '2021-01-01 00:29:59.938400+00:00',\n",
      "               '2021-01-01 00:29:59.948400+00:00',\n",
      "               '2021-01-01 00:29:59.958400+00:00',\n",
      "               '2021-01-01 00:29:59.968400+00:00',\n",
      "               '2021-01-01 00:29:59.978400+00:00',\n",
      "               '2021-01-01 00:29:59.988400+00:00',\n",
      "               '2021-01-01 00:29:59.998400+00:00'],\n",
      "              dtype='datetime64[ns, UTC]', length=180000, freq='10L')\n"
     ]
    }
   ],
   "source": [
    "gather = super_gather[\"AZ.BZN..HHZ\"][0]\n",
    "print(\"gather.data:\", gather.data)           # The raw data array\n",
    "print(\"gather.starttime:\", gather.starttime) # The UTC time of the first temporal sample.\n",
    "print(\"gather.times:\", gather.times)         # The UTC time of each temporal sample."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22e29d8e-13a9-4c71-b09e-5b1f97012b26",
   "metadata": {},
   "source": [
    "A dictionary is returned when retrieving data because regular expressions are permitted when specifying the `tag` value. To demonstrate this, let's add data for one another station to  the file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b3041b69-7e0c-4159-b4db-8b304f7e7a45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tag</th>\n",
       "      <th>start_time</th>\n",
       "      <th>end_time</th>\n",
       "      <th>sampling_rate</th>\n",
       "      <th>npts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AZ.BZN..HHZ</td>\n",
       "      <td>2021-01-01 00:00:00.008400+00:00</td>\n",
       "      <td>2021-01-01 00:59:59.998400+00:00</td>\n",
       "      <td>100.0</td>\n",
       "      <td>360000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AZ.CRY..HHZ</td>\n",
       "      <td>2021-01-01 00:00:00.008400+00:00</td>\n",
       "      <td>2021-01-01 00:59:59.998400+00:00</td>\n",
       "      <td>100.0</td>\n",
       "      <td>360000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           tag                       start_time  \\\n",
       "0  AZ.BZN..HHZ 2021-01-01 00:00:00.008400+00:00   \n",
       "1  AZ.CRY..HHZ 2021-01-01 00:00:00.008400+00:00   \n",
       "\n",
       "                          end_time  sampling_rate    npts  \n",
       "0 2021-01-01 00:59:59.998400+00:00          100.0  360000  \n",
       "1 2021-01-01 00:59:59.998400+00:00          100.0  360000  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "station = \"CRY\"\n",
    "stream = client.get_waveforms(\n",
    "    network,\n",
    "    station,\n",
    "    location,\n",
    "    channel,\n",
    "    start_time,\n",
    "    end_time\n",
    ")\n",
    "for trace in stream:\n",
    "    file_out.timeseries.add(\n",
    "        trace.data,\n",
    "        str(trace.stats.starttime),\n",
    "        trace.stats.sampling_rate,\n",
    "        tag=\".\".join((network, station, location, channel))\n",
    "    )\n",
    "    \n",
    "file_out.timeseries.index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "106df5f6-6403-4364-9d59-02e019cdd7de",
   "metadata": {},
   "source": [
    "Now we can specify a regular expression to select data from both stations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "199b1f11-1208-40a1-a0a2-95555313065d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'AZ.BZN..HHZ': [<hdf5eis.gather.Gather at 0x7f07aaff0fd0>],\n",
       " 'AZ.CRY..HHZ': [<hdf5eis.gather.Gather at 0x7f09aa7035b0>]}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "super_gather = file_out.timeseries[\"AZ.*\", \"2021-01-01T00:00:00Z\": \"2021-01-01T00:30:00Z\"]\n",
    "super_gather"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8971a605-4f2b-4f20-92df-9156ba6d9888",
   "metadata": {},
   "source": [
    "Now that we can add and retrieve timeseries data, let's get the corresponding station metadata from IRIS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2470bf9d-8ccf-4c1a-a843-6635d3a8d045",
   "metadata": {},
   "outputs": [],
   "source": [
    "inventory = sum(*[\n",
    "    client.get_stations(\n",
    "        network=network, \n",
    "        station=station, \n",
    "        location=location, \n",
    "        channel=channel\n",
    "    )\n",
    "    for station in (\"BZN\", \"CRY\")\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84edd1f3-8205-4cea-b27b-a445df0a0de1",
   "metadata": {},
   "source": [
    "We can write this metadata to STATIONXML format using a buffer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cac69885-4d31-4453-b38f-baeb5fb8a0b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'<?xml version=\\'1.0\\' encoding=\\'UTF-8\\'?>\\n<FDSNStationXML xmlns=\"http://www.fdsn.org/xml/station/1\" schemaVersion=\"1.1\">\\n  <Source>IRIS-DMC</Source>\\n  <Sender>IRIS-DMC</Sender>\\n  <Module>IRIS WEB SERVICE: fdsnws-station | version: 1.1.48</Module>\\n  <ModuleURI>http://service.iris.edu/fdsnws/station/1/query?network=AZ&amp;station=CRY&amp;location=--&amp;channel=HHZ</ModuleURI>\\n  <Created>2022-06-22T13:54:33.717000Z</Created>\\n  <Network code=\"AZ\" startDate=\"1982-01-01T00:00:00.000000Z\" restrictedStatus=\"open\">\\n    <Description>ANZA Regional Network (ANZA)</Description>\\n    <Identifier type=\"DOI\">10.7914/SN/AZ\\n   </Identifier>\\n    <TotalNumberStations>93</TotalNumberStations>\\n    <SelectedNumberStations>1</SelectedNumberStations>\\n    <Station code=\"CRY\" startDate=\"1982-10-01T00:00:00.000000Z\" restrictedStatus=\"open\">\\n      <Latitude unit=\"DEGREES\">33.5654</Latitude>\\n      <Longitude unit=\"DEGREES\">-116.7373</Longitude>\\n      <Elevation>1128.0</Elevation>\\n      <Site>\\n        <Name>Cary Ranch, Anza, CA, USA</Name>\\n      </Site>\\n      <CreationDate>1982-10-01T00:00:00.000000Z</CreationDate>\\n      <TotalNumberChannels>437</TotalNumberChannels>\\n      <SelectedNumberChannels>0</SelectedNumberChannels>\\n    </Station>\\n  </Network>\\n  <Network code=\"AZ\" startDate=\"1982-01-01T00:00:00.000000Z\" restrictedStatus=\"open\">\\n    <Description>ANZA Regional Network (ANZA)</Description>\\n    <Identifier type=\"DOI\">10.7914/SN/AZ\\n   </Identifier>\\n    <TotalNumberStations>93</TotalNumberStations>\\n    <SelectedNumberStations>1</SelectedNumberStations>\\n    <Station code=\"BZN\" startDate=\"1983-01-20T00:00:00.000000Z\" restrictedStatus=\"open\">\\n      <Latitude unit=\"DEGREES\">33.4915</Latitude>\\n      <Longitude unit=\"DEGREES\">-116.667</Longitude>\\n      <Elevation>1301.0</Elevation>\\n      <Site>\\n        <Name>Buzz Northerns Place, Anza, CA, USA</Name>\\n      </Site>\\n      <CreationDate>1983-01-20T00:00:00.000000Z</CreationDate>\\n      <TotalNumberChannels>383</TotalNumberChannels>\\n      <SelectedNumberChannels>0</SelectedNumberChannels>\\n    </Station>\\n  </Network>\\n</FDSNStationXML>\\n'\n"
     ]
    }
   ],
   "source": [
    "buffer = io.BytesIO()\n",
    "inventory.write(buffer, \"STATIONXML\")\n",
    "buffer.seek(0)\n",
    "stationxml = buffer.read()\n",
    "\n",
    "# stationxml is now a stream of UTF-8 encoded bytes.\n",
    "print(stationxml)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f00540f-c9f9-48d9-bfb8-37d50a169c19",
   "metadata": {},
   "source": [
    "And we can add this byte stream to the `/metadata` group using the `hdf5eis.File.metadata.add()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2823b6d2-58a5-4ee8-ae42-b18a301e8be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_out.metadata.add(stationxml, \"network_as_UTF8_STATIONXML\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f2a5f03-a20e-47be-9e49-6ce8cacf189c",
   "metadata": {},
   "source": [
    "We can retrieve this metadata using dictionary-like syntax."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0073947d-7158-4f35-b6c4-9497cceced76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<?xml version=\\'1.0\\' encoding=\\'UTF-8\\'?>\\n<FDSNStationXML xmlns=\"http://www.fdsn.org/xml/station/1\" schemaVersion=\"1.1\">\\n  <Source>IRIS-DMC</Source>\\n  <Sender>IRIS-DMC</Sender>\\n  <Module>IRIS WEB SERVICE: fdsnws-station | version: 1.1.48</Module>\\n  <ModuleURI>http://service.iris.edu/fdsnws/station/1/query?network=AZ&amp;station=CRY&amp;location=--&amp;channel=HHZ</ModuleURI>\\n  <Created>2022-06-22T13:54:33.717000Z</Created>\\n  <Network code=\"AZ\" startDate=\"1982-01-01T00:00:00.000000Z\" restrictedStatus=\"open\">\\n    <Description>ANZA Regional Network (ANZA)</Description>\\n    <Identifier type=\"DOI\">10.7914/SN/AZ\\n   </Identifier>\\n    <TotalNumberStations>93</TotalNumberStations>\\n    <SelectedNumberStations>1</SelectedNumberStations>\\n    <Station code=\"CRY\" startDate=\"1982-10-01T00:00:00.000000Z\" restrictedStatus=\"open\">\\n      <Latitude unit=\"DEGREES\">33.5654</Latitude>\\n      <Longitude unit=\"DEGREES\">-116.7373</Longitude>\\n      <Elevation>1128.0</Elevation>\\n      <Site>\\n        <Name>Cary Ranch, Anza, CA, USA</Name>\\n      </Site>\\n      <CreationDate>1982-10-01T00:00:00.000000Z</CreationDate>\\n      <TotalNumberChannels>437</TotalNumberChannels>\\n      <SelectedNumberChannels>0</SelectedNumberChannels>\\n    </Station>\\n  </Network>\\n  <Network code=\"AZ\" startDate=\"1982-01-01T00:00:00.000000Z\" restrictedStatus=\"open\">\\n    <Description>ANZA Regional Network (ANZA)</Description>\\n    <Identifier type=\"DOI\">10.7914/SN/AZ\\n   </Identifier>\\n    <TotalNumberStations>93</TotalNumberStations>\\n    <SelectedNumberStations>1</SelectedNumberStations>\\n    <Station code=\"BZN\" startDate=\"1983-01-20T00:00:00.000000Z\" restrictedStatus=\"open\">\\n      <Latitude unit=\"DEGREES\">33.4915</Latitude>\\n      <Longitude unit=\"DEGREES\">-116.667</Longitude>\\n      <Elevation>1301.0</Elevation>\\n      <Site>\\n        <Name>Buzz Northerns Place, Anza, CA, USA</Name>\\n      </Site>\\n      <CreationDate>1983-01-20T00:00:00.000000Z</CreationDate>\\n      <TotalNumberChannels>383</TotalNumberChannels>\\n      <SelectedNumberChannels>0</SelectedNumberChannels>\\n    </Station>\\n  </Network>\\n</FDSNStationXML>\\n'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_out.metadata[\"network_as_UTF8_STATIONXML\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69e261e4-7764-40c6-a14f-f0e370135496",
   "metadata": {},
   "source": [
    "And we can parse the data using `obspy.read_inventory()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e024d43e-a064-4fea-a4e4-dfee15936ef5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Inventory created at 2022-06-22T13:54:33.717000Z\n",
       "\tCreated by: IRIS WEB SERVICE: fdsnws-station | version: 1.1.48\n",
       "\t\t    http://service.iris.edu/fdsnws/station/1/query?network=AZ&station=C...\n",
       "\tSending institution: IRIS-DMC (IRIS-DMC)\n",
       "\tContains:\n",
       "\t\tNetworks (2):\n",
       "\t\t\tAZ (2x)\n",
       "\t\tStations (2):\n",
       "\t\t\tAZ.BZN (Buzz Northerns Place, Anza, CA, USA)\n",
       "\t\t\tAZ.CRY (Cary Ranch, Anza, CA, USA)\n",
       "\t\tChannels (0):\n"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "buffer = io.BytesIO(file_out.metadata[\"network_as_UTF8_STATIONXML\"].encode(\"UTF-8\"))\n",
    "obspy.read_inventory(buffer, format=\"STATIONXML\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b92aa2e-7a8b-40b8-9a9e-5906971cd574",
   "metadata": {},
   "source": [
    "Finally, we can convert the metadata to a `pandas.DataFrame`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5530c668-8db8-4990-9db6-5f68aa341b3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>network</th>\n",
       "      <th>station</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>elevation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AZ</td>\n",
       "      <td>CRY</td>\n",
       "      <td>33.5654</td>\n",
       "      <td>-116.7373</td>\n",
       "      <td>1128.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AZ</td>\n",
       "      <td>BZN</td>\n",
       "      <td>33.4915</td>\n",
       "      <td>-116.6670</td>\n",
       "      <td>1301.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  network station  latitude  longitude  elevation\n",
       "0      AZ     CRY   33.5654  -116.7373     1128.0\n",
       "1      AZ     BZN   33.4915  -116.6670     1301.0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataf = pd.DataFrame(\n",
    "    [\n",
    "        [\n",
    "            network.code, \n",
    "            station.code, \n",
    "            station.latitude, \n",
    "            station.longitude, \n",
    "            station.elevation\n",
    "        ]\n",
    "        for network in inventory for station in network\n",
    "    ],\n",
    "    columns=[\"network\", \"station\", \"latitude\", \"longitude\", \"elevation\"]\n",
    ")\n",
    "dataf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "597eed97-3bdb-49d9-a6bf-8ba50922e8b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/tljh/user/envs/devel/lib/python3.9/site-packages/hdf5eis/core.py:247: UserWarning: \"network\" column has dtype = np.dtype(\"O\"). Interpreting as UTF-8 encoded bytes.\n",
      "  warnings.warn(\n",
      "/opt/tljh/user/envs/devel/lib/python3.9/site-packages/hdf5eis/core.py:247: UserWarning: \"station\" column has dtype = np.dtype(\"O\"). Interpreting as UTF-8 encoded bytes.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>elevation</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>network</th>\n",
       "      <th>station</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1128.0</td>\n",
       "      <td>33.5654</td>\n",
       "      <td>-116.7373</td>\n",
       "      <td>AZ</td>\n",
       "      <td>CRY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1301.0</td>\n",
       "      <td>33.4915</td>\n",
       "      <td>-116.6670</td>\n",
       "      <td>AZ</td>\n",
       "      <td>BZN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   elevation  latitude  longitude network station\n",
       "0     1128.0   33.5654  -116.7373      AZ     CRY\n",
       "1     1301.0   33.4915  -116.6670      AZ     BZN"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_out.metadata.add(dataf, \"network_geometry_as_table\")\n",
    "file_out.metadata[\"network_geometry_as_table\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b82c7870-26e7-4667-b6e4-fe1ad8594625",
   "metadata": {},
   "source": [
    "The `hdf5eis.File.products` attribute behaves exactly as the `metadata` attribute. Let's finish responsibly by closing our file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d7af50dd-8d90-4ace-a0c1-5e5f8a4fcb75",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_out.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05b7bdea-6d59-4c9f-b3e3-1eedb8d2ea00",
   "metadata": {},
   "source": [
    "Note that using the context manager is the canonical way of opening and closing HDF5eis files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "966a76a2-1a81-4b0e-b0e7-f134c158db89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   elevation  latitude  longitude network station\n",
      "0     1128.0   33.5654  -116.7373      AZ     CRY\n",
      "1     1301.0   33.4915  -116.6670      AZ     BZN\n"
     ]
    }
   ],
   "source": [
    "with hdf5eis.File(OUTPUT_DIR.joinpath(\"my_first_file.hdf5\"), mode=\"r\") as file_in:\n",
    "    print(file_in.metadata[\"network_geometry_as_table\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58094fe3-d3d3-4103-ad49-c9dc121ccd8b",
   "metadata": {},
   "source": [
    "That's it!  Those are the basics of adding data to and retrieving it from an HDF5eis file! In the next tutorial, we will learn how to add and retrieve multidimensional arrays and use HDF5eis external linking functionality."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:devel]",
   "language": "python",
   "name": "conda-env-devel-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
