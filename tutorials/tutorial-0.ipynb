{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4e0f84e7-5a8e-481d-b1ec-2bb71059f72b",
   "metadata": {},
   "source": [
    "# Tutorial-0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e96100d-f5d6-498c-bdd5-974c295b537a",
   "metadata": {},
   "source": [
    "This first exercise demonstrates how to create an empty HDF5eis file and add a single channel of data to it. To begin, let's import some necessary packages for this tutorial and create a directory where we can write some data files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8a6571a-e33e-498e-a71b-d082253741a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install obspy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4bd495b-a6b6-425b-9039-dac479f6e184",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard library imports\n",
    "import io\n",
    "import pathlib\n",
    "import tempfile\n",
    "\n",
    "# Third-party imports\n",
    "import hdf5eis\n",
    "import obspy.clients.fdsn\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "tmp_dir = tempfile.TemporaryDirectory()\n",
    "OUTPUT_DIR = pathlib.Path(tmp_dir.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80724a5f-4acb-4a16-a470-60177ee43143",
   "metadata": {},
   "source": [
    "Core functionality for manipulating HDF5eis files is accessed via the `hdf5eis.File` class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be9328e4-bb5b-4ca1-bdf5-1382fc1e1325",
   "metadata": {},
   "outputs": [],
   "source": [
    "hdf5eis.File?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a491904-6af5-4514-af94-b989f3ddf202",
   "metadata": {},
   "source": [
    "Let's create an empty HDF5eis file. The default `mode` is `\"r\"`, so to create a new file we need to specify `mode=\"w\"` or `mode=\"a\"`. Note that the `hdf5eis.File` class inherits from the `h5py.File` class and passes `*args` and `**kwargs` to its super-class initializer. Any valid positional or keyword arguments for the `h5py.File` intializer are therefore valid for `hdf5eis.File` as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "579d7ff9-ed12-45ac-8598-bb215ca3b52e",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_out = hdf5eis.File(OUTPUT_DIR.joinpath(\"my_first_file.hdf5\"), mode='w', overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "489f42ef-6b05-4f25-a0a5-deb174c7ba13",
   "metadata": {},
   "source": [
    "`hdf5eis.File` instances have three properties (`timeseries`, `metadata`, and `products`) which provide functionality to manipulate the groups by the same name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb07356a-efbb-4fee-8446-20158872b7e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_out.timeseries?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9142f25e-3bf1-4d5b-90fe-dab0604ed039",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_out.metadata?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "480034f8-06d9-4947-b545-4cd46038de13",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_out.products?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d10fc9b3-52f9-4490-b573-b729fb8e6892",
   "metadata": {},
   "source": [
    "The `hdf5eis.File.timeseries` property has an `index` property that records the contents of the group. At present, it is empty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4b9a4db-47b5-4bb4-a8ef-0685a3cd1df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_out.timeseries.index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5502c464-411e-4b56-b320-0eecabe16ac3",
   "metadata": {},
   "source": [
    "Let's download some timeseries data to add to the file. We will download one hour of data from IRIS for channel `AZ.BZN..HHZ`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78fc04c3-878c-47f9-80cf-01aebfda17f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "network = \"AZ\"\n",
    "station = \"BZN\"\n",
    "location = \"\"\n",
    "channel = \"HHZ\"\n",
    "start_time = obspy.UTCDateTime(\"2021-01-01T00:00:00Z\")\n",
    "end_time = obspy.UTCDateTime(\"2021-01-01T01:00:00Z\")\n",
    "client = obspy.clients.fdsn.Client()\n",
    "stream = client.get_waveforms(\n",
    "    network,\n",
    "    station,\n",
    "    location,\n",
    "    channel,\n",
    "    start_time,\n",
    "    end_time\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9df6f6de-3800-45ef-97a4-63275087fb7d",
   "metadata": {},
   "source": [
    "We can add the data using the `add` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26849181-cdb1-4d28-b5a9-4ca6c6fb2f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_out.timeseries.add?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "456e2681-45a8-4ce8-99e5-819a0095d961",
   "metadata": {},
   "outputs": [],
   "source": [
    "for trace in stream:\n",
    "    file_out.timeseries.add(\n",
    "        trace.data,\n",
    "        str(trace.stats.starttime),\n",
    "        trace.stats.sampling_rate,\n",
    "        tag=\".\".join((network, station, location, channel))\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "228e983a-84d4-41de-a8cf-70e62eea231c",
   "metadata": {},
   "source": [
    "Now we can see that there is a corresponding row in the timeseries index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "803fb359-d922-4190-88ef-1ddeff2062e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_out.timeseries.index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07f78782-31ab-4728-b4a6-c57e1c281f0d",
   "metadata": {},
   "source": [
    "We can retrieve the data now using a hybrid of dictionary-like and array-slicing syntax."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caa15b3c-a474-41db-82be-737ed8f7a147",
   "metadata": {},
   "outputs": [],
   "source": [
    "super_gather = file_out.timeseries[\"AZ.BZN..HHZ\", \"2021-01-01T00:00:00Z\": \"2021-01-01T00:30:00Z\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f412978b-2781-4940-9840-2036ac7a479a",
   "metadata": {},
   "source": [
    "Timeseries data are returned as a dictionary in which the key is the `tag` associated with the corresponding value and the value is a list of `hdf5eis.Gather` objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0f2bc4c-171a-43f3-abf3-8808cb272f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "super_gather"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cc415a0-eb58-40cd-afbf-8859230b32d4",
   "metadata": {},
   "source": [
    "Each `hdf5eis.Gather` object has a number of descriptive properties (a subset is demonstrated here)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3af25005-1d3b-43a6-b211-7c28144f9b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "gather = super_gather[\"AZ.BZN..HHZ\"][0]\n",
    "print(\"gather.data:\", gather.data)           # The raw data array\n",
    "print(\"gather.starttime:\", gather.start_time) # The UTC time of the first temporal sample.\n",
    "print(\"gather.times:\", gather.times)         # The UTC time of each temporal sample."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22e29d8e-13a9-4c71-b09e-5b1f97012b26",
   "metadata": {},
   "source": [
    "A dictionary is returned when retrieving data because regular expressions are permitted when specifying the `tag` value. To demonstrate this, let's add data for one another station to  the file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3041b69-7e0c-4159-b4db-8b304f7e7a45",
   "metadata": {},
   "outputs": [],
   "source": [
    "station = \"CRY\"\n",
    "stream = client.get_waveforms(\n",
    "    network,\n",
    "    station,\n",
    "    location,\n",
    "    channel,\n",
    "    start_time,\n",
    "    end_time\n",
    ")\n",
    "for trace in stream:\n",
    "    file_out.timeseries.add(\n",
    "        trace.data,\n",
    "        str(trace.stats.starttime),\n",
    "        trace.stats.sampling_rate,\n",
    "        tag=\".\".join((network, station, location, channel))\n",
    "    )\n",
    "    \n",
    "file_out.timeseries.index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "106df5f6-6403-4364-9d59-02e019cdd7de",
   "metadata": {},
   "source": [
    "Now we can specify a regular expression to select data from both stations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "199b1f11-1208-40a1-a0a2-95555313065d",
   "metadata": {},
   "outputs": [],
   "source": [
    "super_gather = file_out.timeseries[\"AZ.*\", \"2021-01-01T00:00:00Z\": \"2021-01-01T00:30:00Z\"]\n",
    "super_gather"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8971a605-4f2b-4f20-92df-9156ba6d9888",
   "metadata": {},
   "source": [
    "Now that we can add and retrieve timeseries data, let's get the corresponding station metadata from IRIS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2470bf9d-8ccf-4c1a-a843-6635d3a8d045",
   "metadata": {},
   "outputs": [],
   "source": [
    "inventory = sum(*[\n",
    "    client.get_stations(\n",
    "        network=network, \n",
    "        station=station, \n",
    "        location=location, \n",
    "        channel=channel\n",
    "    )\n",
    "    for station in (\"BZN\", \"CRY\")\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84edd1f3-8205-4cea-b27b-a445df0a0de1",
   "metadata": {},
   "source": [
    "We can write this metadata to STATIONXML format using a buffer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cac69885-4d31-4453-b38f-baeb5fb8a0b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "buffer = io.BytesIO()\n",
    "inventory.write(buffer, \"STATIONXML\")\n",
    "buffer.seek(0)\n",
    "stationxml = buffer.read()\n",
    "\n",
    "# stationxml is now a stream of UTF-8 encoded bytes.\n",
    "stationxml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f00540f-c9f9-48d9-bfb8-37d50a169c19",
   "metadata": {},
   "source": [
    "And we can add this byte stream to the `/metadata` group using the `hdf5eis.File.metadata.add()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2823b6d2-58a5-4ee8-ae42-b18a301e8be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_out.metadata.add(stationxml, \"network_as_UTF8_STATIONXML\", fmt='STATIONXML')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f2a5f03-a20e-47be-9e49-6ce8cacf189c",
   "metadata": {},
   "source": [
    "We can retrieve this metadata using dictionary-like syntax."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0073947d-7158-4f35-b6c4-9497cceced76",
   "metadata": {},
   "outputs": [],
   "source": [
    "string, fmt = file_out.metadata[\"network_as_UTF8_STATIONXML\"]\n",
    "print(string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "279e3e87-3c74-43bf-a162-5e93416dbf7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fmt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69e261e4-7764-40c6-a14f-f0e370135496",
   "metadata": {},
   "source": [
    "And we can parse the data using `obspy.read_inventory()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e024d43e-a064-4fea-a4e4-dfee15936ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "buffer = io.BytesIO(string.encode(\"UTF-8\"))\n",
    "obspy.read_inventory(buffer, format=fmt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b92aa2e-7a8b-40b8-9a9e-5906971cd574",
   "metadata": {},
   "source": [
    "Finally, we can convert the metadata to a `pandas.DataFrame`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5530c668-8db8-4990-9db6-5f68aa341b3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataf = pd.DataFrame(\n",
    "    [\n",
    "        [\n",
    "            network.code, \n",
    "            station.code, \n",
    "            station.latitude, \n",
    "            station.longitude, \n",
    "            station.elevation\n",
    "        ]\n",
    "        for network in inventory for station in network\n",
    "    ],\n",
    "    columns=[\"network\", \"station\", \"latitude\", \"longitude\", \"elevation\"]\n",
    ")\n",
    "dataf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "597eed97-3bdb-49d9-a6bf-8ba50922e8b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_out.metadata.add(dataf, \"network_geometry_as_table\")\n",
    "table, fmt = file_out.metadata[\"network_geometry_as_table\"]\n",
    "table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b82c7870-26e7-4667-b6e4-fe1ad8594625",
   "metadata": {},
   "source": [
    "The `hdf5eis.File.products` attribute behaves exactly as the `metadata` attribute. Let's finish responsibly by closing our file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7af50dd-8d90-4ace-a0c1-5e5f8a4fcb75",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_out.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05b7bdea-6d59-4c9f-b3e3-1eedb8d2ea00",
   "metadata": {},
   "source": [
    "Note that using the context manager is the canonical way of opening and closing HDF5eis files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "966a76a2-1a81-4b0e-b0e7-f134c158db89",
   "metadata": {},
   "outputs": [],
   "source": [
    "with hdf5eis.File(OUTPUT_DIR.joinpath(\"my_first_file.hdf5\"), mode=\"r\") as file_in:\n",
    "    table, fmt = file_in.metadata[\"network_geometry_as_table\"]\n",
    "    \n",
    "table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58094fe3-d3d3-4103-ad49-c9dc121ccd8b",
   "metadata": {},
   "source": [
    "That's it!  Those are the basics of adding data to and retrieving it from an HDF5eis file! In the next tutorial, we will learn how to add and retrieve multidimensional arrays and use HDF5eis external linking functionality."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
